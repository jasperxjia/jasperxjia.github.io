<!DOCTYPE html>
<html>
<head>
    <meta charset='utf-8'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <title>Accessible AR Interaction for VIP (vision impaired people)</title>
    <link rel="stylesheet" href="">

    <!-- Import Aframe and AR.js -->
    <script src="https://aframe.io/releases/0.8.0/aframe.min.js"></script> 
    <script src="./scripts/aframe-ar.js"></script>

    <!-- Import Haptic API -->
    <script type="text/javascript" src="//raw.githubusercontent.com/shantanubala/haptics.js/master/haptics.js"></script>

    <!-- Import Swipe-Events API -->
    <script type="text/javascript" src="./scripts/swiped-events.min.js"></script>

</head>


<!-- AR scene Render based on AFRAME onclick="speechSynthesis.speak(new SpeechSynthesisUtterance('find objects'))" -->
<body style='margin: 0; overflow: hidden;'>
  <a-scene  
    cursor="fuse:false; rayOrigin: mouse" embedded arjs="sourceType: webcam; trackingMethod: best;" vr-mode-ui="false" >

    <!--Asset Management System (not rendered unless called)-->
    <a-assets>
      <a-asset-item id="asset1" src="./assets/models/lowpoly_pin/scene.gltf"></a-asset-item>
      <a-asset-item id="asset2" src="./assets/models/cloud.gltf"></a-asset-item>
      <a-asset-item id="asset3" src="./assets/models/window.gltf"></a-asset-item>
    </a-assets>
    
    <!--Add a Marker where assets load onto-->
    <a-marker accessible preset='hiro' alt="A pin!">
      <a-entity  gltf-model="#asset1" scale="0.8 0.8 0.8" position="0 0 0" rotation="-90 0 0"></a-entity>
    </a-marker>

    <a-marker markerevents clickable-model type="pattern" url='./assets/patterns/cloud.patt' alt="A cloud!">
      <a-entity  gltf-model="#asset2" scale="0.5 0.5 0.5" position="0 0 0" rotation="-90 0 0" material="color: white"></a-entity>
    </a-marker>

    <a-marker markerevents clickable-model preset='kanji' alt="A window!">
      <a-entity  gltf-model="#asset3" scale="0.5 0.5 0.5" position="0 0 0" rotation="-90 0 0" material="color: white"></a-entity>
    </a-marker>

    
    <!--a-entity geometry="primitive: plane;" material="opacity: 0">
      <a-text value="placeholder" visible="false" id="text-box" position="-0.425 0.293 -0.531" rotation="-84.347 54.042 -51.893"></a-text>
    </a-entity-->

    <!--Add a Camera-->
    <a-entity camera></a-entity>
  </a-scene>



  <!-- Script for VIP interaction -->
  <script>
        
//Give this conponenet to marker to show alerts found and lost events
   //Give this conponenet to marker to show alerts found and lost events
AFRAME.registerComponent('accessible', {
  init: function () {
    var marker = this.el;
    var readmarker = marker.getAttribute('alt'); 
    var scene = document.querySelector('body'); 
    var gesture = new Hammer(scene);

  //Tap behaviour
        gesture.on('tap', function(ev) {
          if(marker.object3D.visible == false){
            speechSynthesis.cancel();
            speechSynthesis.speak(new SpeechSynthesisUtterance('Look Around')); //cue for users to look around for an object
            window.navigator.vibrate(200);} 
      else if(marker.object3D.visible == true) {
        speechSynthesis.cancel();
        speechSynthesis.speak(new SpeechSynthesisUtterance(readmarker)); //description for object
        window.navigator.vibrate(200);
      }});
 //Double tap behaviour 
      gesture.on('doubletap', function(ev) {
        if(marker.object3D.visible == false){
            speechSynthesis.cancel();
            speechSynthesis.speak(new SpeechSynthesisUtterance('Look Around')); //cue for users to look around for an object
            window.navigator.vibrate(200);} 
      else if(marker.object3D.visible == true) {
        speechSynthesis.cancel();
        speechSynthesis.speak(new SpeechSynthesisUtterance('page reload')); //description for function
        window.navigator.vibrate(200);
        location.reload();
      }});

  //Behaviour when objects are found
    marker.addEventListener('markerFound', function() {

      var markerId = marker.id;
      speechSynthesis.cancel();
      speechSynthesis.speak(new SpeechSynthesisUtterance(readmarker.concat('Double tap to interact'))); //cue for users to interact with the detected object
        
    });


  //Behaviour when objects are lost 
    marker.addEventListener('markerLost', function() {
      speechSynthesis.cancel();
      speechSynthesis.speak(new SpeechSynthesisUtterance('Nothing here')); //cue for users to figure out where the objects are potentially located in relation to camera 
      window.navigator.vibrate(200);   
      
    });

    

   /* marker.addEventListener('nomarker', function() {
      //alert('markerfound'); // For testing
      scene.addEventListener('click', function () {
      speechSynthesis.cancel();
      speechSynthesis.speak(new SpeechSynthesisUtterance('Look Around')); 
      window.navigator.vibrate(200);          
    });*/
 
  }
});
 </script>

</body>
</html>
